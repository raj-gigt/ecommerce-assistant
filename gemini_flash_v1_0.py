# -*- coding: utf-8 -*-
"""GEMINI_FLASH_V1.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B89Gk7tHIL1o8uTpOIN3AlzvLFQxrHSN
"""

import google.generativeai as genai
from PIL import Image
import io
import json
import sys
import os

GOOGLE_API_KEY="AIzaSyAbBegFvGVsa6K9V-y5blFYefw2kHM9c-k"

if not GOOGLE_API_KEY:
    print("Error: GOOGLE_API_KEY environment variable not set.")
    print("Please set it using: export GOOGLE_API_KEY='YOUR_API_KEY'")
    sys.exit(1)

genai.configure(api_key=GOOGLE_API_KEY)

# Define the generation configuration
# We specifically ask the model to output JSON
generation_config = {
    "temperature": 0.1, # Keep it low for factual responses
    "top_p": 1,
    "top_k": 32,
    "max_output_tokens": 4096,
}

model = genai.GenerativeModel(model_name='gemini-1.5-flash-001', # Or 'gemini-1.5-pro-001' for potentially better results but higher cost/latency
                              generation_config=generation_config)

# Start a chat session to maintain context
chat = model.start_chat(history=[])

# --- Helper Function to prepare image for API ---
def get_image_part(image_path):
    """Reads an image file and prepares it as an API part."""
    try:
        img = Image.open(image_path).convert('RGB')
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format='JPEG') # Or PNG, depending on preference/original
        img_byte_arr = img_byte_arr.getvalue()

        image_part = {
            "mime_type": "image/jpeg", # Adjust mime type if using PNG
            "data": img_byte_arr
        }
        return image_part
    except FileNotFoundError:
        print(f"Error: Image file not found at {image_path}")
        return None
    except Exception as e:
        print(f"Error processing image: {e}")
        return None

initial_prompt = """
You are an AI agent that recommends products on Amazon.in based on user input (images and text).
Your task is:
1.  **Initial Input:** Analyze the provided image and any accompanying text. Identify the main product from the image and its key visual traits. Incorporate any specific requirements from the text input (like price range, brands) into the traits. Generate an Amazon.in search URL using the identified product and traits.
2.  **Subsequent Input:** When the user provides text input *without* an image, treat it as a refinement or additional requirement for the *previously identified product and traits*. Update the traits and generate a *new* Amazon.in search URL based on the *updated* traits and the (potentially updated) item name.
3.  **Output Format:** You *must* output only a single JSON object in the following exact format. Do not include any other text, explanation, or formatting outside this JSON object:
    ```json
    {
    "itemname": "Identified product name (e.g., Men's Jeans)",
    "traits": "Comma-separated list of relevant traits (e.g., Dark Blue, Slim Fit, Rolled Cuffs, Peter England, Price Range 1500-2000)",
    "searchlink": "https://www.amazon.in/s?k=search+query+based+on+itemname+and+traits+with+spaces+replaced+by+plus"
    }
    ```
4.  **Search Link Construction:** The search link should be `https://www.amazon.in/s?k=`, followed by the item name and traits joined by spaces, with all spaces replaced by `+`.
5.  **Constraint:** Generate *only* the JSON object.
"""

# --- Main Interaction Loop ---

def process_input(image_path=None, text_query=None):
    """Sends input (image and/or text) to the model and returns the response."""
    global chat # Use the global chat session

    content_parts = []

    # Add the initial prompt only for the very first turn
    if not chat.history:
         content_parts.append(initial_prompt)

    # Add image part if provided
    if image_path:
        img_part = get_image_part(image_path)
        if img_part:
            content_parts.append(img_part)
        else:
            print("Could not process image. Skipping this turn.")
            return None # Indicate failure

    # Add text part if provided
    if text_query:
        content_parts.append(text_query)

    if not content_parts:
        print("No input provided.")
        return None

    try:
        # Send the content to the chat model. The chat history is automatically managed.
        response = chat.send_message(content_parts)

        # Attempt to parse the JSON response
        try:
            # The model should output only the JSON string
            response_json = json.loads(response.text)
            # Basic validation of the JSON structure
            if all(key in response_json for key in ["itemname", "traits", "searchlink"]):
                 return response_json
            else:
                print("Warning: Response structure is not as expected.")
                print(f"Raw response text: {response.text}")
                return None # Indicate invalid structure
        except json.JSONDecodeError:
            print(f"Warning: Could not parse response as JSON.")
            print(f"Raw response text: {response.text}")
            # Even if not valid JSON, return the text so the user sees it
            return {"error": "Invalid JSON response from API", "raw_text": response.text}

    except Exception as e:
        print(f"An error occurred during API call: {e}")
        return None # Indicate API call failure

# Configure the API key
# Replace with your actual API key or set it as an environment variable
# It's recommended to set it as an environment variable for security
# export GOOGLE_API_KEY='YOUR_API_KEY'


# Initialize the model
# Using gemini-pro-vision for image+text input


# --- Initial Prompt (explains the persona, task, format) ---
# This initial prompt is crucial for setting the rules.
# It will be sent along with the first image and text input.

# --- Script Execution ---

if __name__ == "__main__":
    print("Amazon Product Recommender (using Gemini API)")
    print("Enter 'quit' to exit.")
    print("For the first query, provide the image path and initial text.")
    print("Example: path/to/your/image.jpg suggest in price range of 1500-2000 rupees")

    # Get the first input which can include an image path and text
    first_input = input("Enter image path (optional) and initial query: ").strip()

    image_file = None
    initial_text = first_input

    # Simple check to see if the first part of the input looks like a file path
    # This is a basic heuristic; a real app would have better UI for file upload
    if os.path.exists(first_input.split()[0]):
         image_file = first_input.split()[0]
         initial_text = " ".join(first_input.split()[1:]) # Rest is text query

    print("\nProcessing initial input...")
    response_data = process_input(image_path=image_file, text_query=initial_text)

    if response_data:
        # print the JSON output only
        print(json.dumps(response_data, indent=4))
    else:
        print("Failed to get a valid response. Please try again.")

    # Start the loop for follow-up text queries
    while True:
        user_query = input("\nEnter follow-up query (or 'quit' to exit): ").strip()

        if user_query.lower() == 'quit':
            break

        if not user_query:
            print("No input received. Please enter a query or 'quit'.")
            continue

        print("\nProcessing follow-up query...")
        # For follow-up, only send the text query
        response_data = process_input(text_query=user_query)

        if response_data:
            # print the JSON output only
             print(json.dumps(response_data, indent=4))
        else:
            print("Failed to get a valid response. Please try again.")

    print("\nExiting.")

